{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Modified VGG-16 Architecture for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16:\n",
    "    def __init__(self, img_size, num_categories, learning_rate):\n",
    "        self._model = keras.models.Sequential()\n",
    "        self._add_conv_2d_filter(64, input_shape=img_size, duplicate=2)\n",
    "        self._add_max_pooling_layer()\n",
    "        self._add_conv_2d_filter(128, duplicate=2)\n",
    "        self._add_max_pooling_layer()\n",
    "        self._add_conv_2d_filter(256, duplicate=3)\n",
    "        self._add_max_pooling_layer()\n",
    "#         self._add_conv_2d_filter(512, duplicate=3)\n",
    "#         self._add_max_pooling_layer()\n",
    "#         self._add_conv_2d_filter(512, duplicate=3)\n",
    "#         self._add_max_pooling_layer()\n",
    "        self._model.add(keras.layers.Flatten())\n",
    "        self._add_dense_layer(2048, 'relu')\n",
    "        self._add_dense_layer(2048, 'relu')\n",
    "        self._add_dense_layer(num_categories, 'softmax')\n",
    "        self._optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "        self._model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=self._optimizer,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    def train(self, x, y, batch_size, epochs, dev_ratio=0.2):\n",
    "        self._model.fit(\n",
    "            x=x, y=y, batch_size=batch_size, epochs=epochs, validation_split=dev_ratio, verbose=1\n",
    "        )\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.argmax(self._model.predict(x), axis=-1)\n",
    "    \n",
    "    def print_model_summary(self):\n",
    "        self._model.summary()\n",
    "\n",
    "    def _add_conv_2d_filter(self, filters, input_shape=None, duplicate=1):\n",
    "        for idx in range(duplicate):\n",
    "            kwargs = {\n",
    "                'filters': filters,\n",
    "                'kernel_size': 3,\n",
    "                'strides': 1,\n",
    "                'padding': 'same',\n",
    "                'data_format': 'channels_last',\n",
    "                'activation': 'relu',\n",
    "                'kernel_initializer': 'glorot_normal'\n",
    "            }\n",
    "            if input_shape is not None and idx == 0:\n",
    "                kwargs['input_shape'] = input_shape\n",
    "            self._model.add(keras.layers.Conv2D(**kwargs))\n",
    "    \n",
    "    def _add_max_pooling_layer(self):\n",
    "        self._model.add(keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    \n",
    "    def _add_dense_layer(self, units, activation):\n",
    "        self._model.add(keras.layers.Dense(units=units, activation=activation, kernel_initializer='glorot_normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/mnist\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(\n",
    "    mnist.train.images.shape[1:],\n",
    "    mnist.train.labels.shape[-1],\n",
    "    1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4720640   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 10,671,818\n",
      "Trainable params: 10,671,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.print_model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44000 samples, validate on 11000 samples\n",
      "Epoch 1/100\n",
      "44000/44000 [==============================] - 9s 207us/step - loss: 0.4833 - acc: 0.8423 - val_loss: 0.0711 - val_acc: 0.9779\n",
      "Epoch 2/100\n",
      "44000/44000 [==============================] - 6s 131us/step - loss: 0.0605 - acc: 0.9810 - val_loss: 0.0591 - val_acc: 0.9810\n",
      "Epoch 3/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0367 - acc: 0.9880 - val_loss: 0.0359 - val_acc: 0.9894\n",
      "Epoch 4/100\n",
      "44000/44000 [==============================] - 6s 135us/step - loss: 0.0252 - acc: 0.9922 - val_loss: 0.0379 - val_acc: 0.9891\n",
      "Epoch 5/100\n",
      "44000/44000 [==============================] - 6s 135us/step - loss: 0.0235 - acc: 0.9927 - val_loss: 0.0413 - val_acc: 0.9892\n",
      "Epoch 6/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0181 - acc: 0.9941 - val_loss: 0.0323 - val_acc: 0.9905\n",
      "Epoch 7/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0304 - val_acc: 0.9924\n",
      "Epoch 8/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0359 - val_acc: 0.9902\n",
      "Epoch 9/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0305 - val_acc: 0.9918\n",
      "Epoch 10/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.0398 - val_acc: 0.9895\n",
      "Epoch 11/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0333 - val_acc: 0.9924\n",
      "Epoch 12/100\n",
      "44000/44000 [==============================] - 6s 134us/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0365 - val_acc: 0.9924\n",
      "Epoch 13/100\n",
      "44000/44000 [==============================] - 6s 133us/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0350 - val_acc: 0.9918\n",
      "Epoch 14/100\n",
      "44000/44000 [==============================] - 6s 132us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0333 - val_acc: 0.9923\n",
      "Epoch 15/100\n",
      "44000/44000 [==============================] - 6s 136us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0343 - val_acc: 0.9920\n",
      "Epoch 16/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0433 - val_acc: 0.9910\n",
      "Epoch 17/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0333 - val_acc: 0.9925\n",
      "Epoch 18/100\n",
      "44000/44000 [==============================] - 6s 130us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9942\n",
      "Epoch 19/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0105 - acc: 0.9966 - val_loss: 0.0389 - val_acc: 0.9905\n",
      "Epoch 20/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0414 - val_acc: 0.9918\n",
      "Epoch 21/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0376 - val_acc: 0.9909\n",
      "Epoch 22/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0363 - val_acc: 0.9922\n",
      "Epoch 23/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0415 - val_acc: 0.9908\n",
      "Epoch 24/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0382 - val_acc: 0.9917\n",
      "Epoch 25/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0424 - val_acc: 0.9916\n",
      "Epoch 26/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0495 - val_acc: 0.9915\n",
      "Epoch 27/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0420 - val_acc: 0.9924\n",
      "Epoch 28/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0365 - val_acc: 0.9916\n",
      "Epoch 29/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0439 - val_acc: 0.9911\n",
      "Epoch 30/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0383 - val_acc: 0.9923\n",
      "Epoch 31/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.0447 - val_acc: 0.9912\n",
      "Epoch 32/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.0366 - val_acc: 0.9913\n",
      "Epoch 33/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0475 - val_acc: 0.9914\n",
      "Epoch 34/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0430 - val_acc: 0.9914\n",
      "Epoch 35/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0370 - val_acc: 0.9919\n",
      "Epoch 36/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.0362 - val_acc: 0.9930\n",
      "Epoch 37/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0487 - val_acc: 0.9906\n",
      "Epoch 38/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0395 - val_acc: 0.9928\n",
      "Epoch 39/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0580 - val_acc: 0.9905\n",
      "Epoch 40/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0412 - val_acc: 0.9925\n",
      "Epoch 41/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0478 - val_acc: 0.9913\n",
      "Epoch 42/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0389 - val_acc: 0.9935\n",
      "Epoch 43/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0498 - val_acc: 0.9925\n",
      "Epoch 44/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0571 - val_acc: 0.9909\n",
      "Epoch 45/100\n",
      "44000/44000 [==============================] - 6s 130us/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0428 - val_acc: 0.9927\n",
      "Epoch 46/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0427 - val_acc: 0.9903\n",
      "Epoch 47/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0449 - val_acc: 0.9916\n",
      "Epoch 48/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0475 - val_acc: 0.9921\n",
      "Epoch 49/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 8.8834e-04 - acc: 0.9997 - val_loss: 0.0481 - val_acc: 0.9928\n",
      "Epoch 50/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 8.2090e-04 - acc: 0.9997 - val_loss: 0.0549 - val_acc: 0.9913\n",
      "Epoch 51/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0089 - acc: 0.9981 - val_loss: 0.0398 - val_acc: 0.9927\n",
      "Epoch 52/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0558 - val_acc: 0.9911\n",
      "Epoch 53/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0470 - val_acc: 0.9915\n",
      "Epoch 54/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0455 - val_acc: 0.9935\n",
      "Epoch 55/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0450 - val_acc: 0.9928\n",
      "Epoch 56/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0498 - val_acc: 0.9932\n",
      "Epoch 57/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0526 - val_acc: 0.9915\n",
      "Epoch 58/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0476 - val_acc: 0.9903\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0414 - val_acc: 0.9925\n",
      "Epoch 60/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0534 - val_acc: 0.9921\n",
      "Epoch 61/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 8.4731e-04 - acc: 0.9997 - val_loss: 0.0470 - val_acc: 0.9936\n",
      "Epoch 62/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0488 - val_acc: 0.9905\n",
      "Epoch 63/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0051 - acc: 0.9989 - val_loss: 0.0489 - val_acc: 0.9912\n",
      "Epoch 64/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0392 - val_acc: 0.9937\n",
      "Epoch 65/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0450 - val_acc: 0.9922\n",
      "Epoch 66/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0539 - val_acc: 0.9913\n",
      "Epoch 67/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0554 - val_acc: 0.9914\n",
      "Epoch 68/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0461 - val_acc: 0.9925\n",
      "Epoch 69/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0481 - val_acc: 0.9936\n",
      "Epoch 70/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0396 - val_acc: 0.9936\n",
      "Epoch 71/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 5.7342e-04 - acc: 0.9998 - val_loss: 0.0481 - val_acc: 0.9939\n",
      "Epoch 72/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 7.5360e-05 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 0.9939\n",
      "Epoch 73/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.3314e-05 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9939\n",
      "Epoch 74/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.3462e-05 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 0.9941\n",
      "Epoch 75/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 2.6114e-06 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 0.9942\n",
      "Epoch 76/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 3.6814e-07 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 0.9941\n",
      "Epoch 77/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 3.1170e-07 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9941\n",
      "Epoch 78/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 2.7721e-07 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 0.9942\n",
      "Epoch 79/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 2.5256e-07 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 0.9942\n",
      "Epoch 80/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 2.3358e-07 - acc: 1.0000 - val_loss: 0.0562 - val_acc: 0.9942\n",
      "Epoch 81/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 2.1894e-07 - acc: 1.0000 - val_loss: 0.0563 - val_acc: 0.9942\n",
      "Epoch 82/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 2.0771e-07 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9942\n",
      "Epoch 83/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.9817e-07 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9942\n",
      "Epoch 84/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.9024e-07 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 0.9942\n",
      "Epoch 85/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.8362e-07 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 0.9942\n",
      "Epoch 86/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.7794e-07 - acc: 1.0000 - val_loss: 0.0569 - val_acc: 0.9942\n",
      "Epoch 87/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.7300e-07 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 0.9942\n",
      "Epoch 88/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.6874e-07 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 0.9942\n",
      "Epoch 89/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.6494e-07 - acc: 1.0000 - val_loss: 0.0572 - val_acc: 0.9942\n",
      "Epoch 90/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.6158e-07 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 0.9942\n",
      "Epoch 91/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.5861e-07 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 0.9942\n",
      "Epoch 92/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.5600e-07 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 0.9942\n",
      "Epoch 93/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.5356e-07 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 0.9943\n",
      "Epoch 94/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.5139e-07 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9943\n",
      "Epoch 95/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.4941e-07 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 0.9943\n",
      "Epoch 96/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.4758e-07 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 0.9943\n",
      "Epoch 97/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.4589e-07 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9943\n",
      "Epoch 98/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.4438e-07 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9943\n",
      "Epoch 99/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.4297e-07 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9943\n",
      "Epoch 100/100\n",
      "44000/44000 [==============================] - 6s 129us/step - loss: 1.4167e-07 - acc: 1.0000 - val_loss: 0.0581 - val_acc: 0.9943\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    x=mnist.train.images,\n",
    "    y=mnist.train.labels,\n",
    "    batch_size=512,\n",
    "    epochs=100,\n",
    "    dev_ratio=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(mnist.test.images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mnist.test.labels[:10], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.count_nonzero(model.predict(mnist.test.images) == np.argmax(mnist.test.labels, axis=-1).ravel()) / mnist.test.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
